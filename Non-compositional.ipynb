{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Композициональность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports of all neccessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from gensim.models import KeyedVectors\n",
    "from scipy.spatial import distance\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# import tensorflow_text\n",
    "from nltk import word_tokenize\n",
    "import copy\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import FillMaskPipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('compounds_AN_top10000.csv')\n",
    "df = df.drop(labels=['Unnamed: 0'], axis=1)\n",
    "df = df.drop(labels=[5593], axis=0)\n",
    "df['Композициональность'] = pd.to_numeric(df['Композициональность'])\n",
    "df = pd.concat([df[df['Композициональность'] == 0], \n",
    "                df[df['Композициональность'] == 1][:248],\n",
    "                df[df['Композициональность'] == 2][:248]])\n",
    "df = df.iloc[:, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization and PoS tagging via `pymorphy2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(word, pos):\n",
    "    variants = m.parse(word.lower())\n",
    "    for var in variants:\n",
    "        if pos in var.tag:\n",
    "            if pos == 'NOUN':\n",
    "                return var.normal_form + '_' + pos\n",
    "            else:\n",
    "                return var.normal_form + '_' + 'ADJ'\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_bigram(lemma1, lemma2):\n",
    "    lemma1 = lemma1.split('_')\n",
    "    lemma2 = lemma2.split('_')\n",
    "    return lemma1[0] + '::' + lemma2[0] + '_' + lemma1[1] + lemma2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Lemma 1'] = df['Часть 1'].apply(lambda x: analysis(x, 'ADJF'))\n",
    "df['Lemma 2'] = df['Часть 2'].apply(lambda x: analysis(x, 'NOUN'))\n",
    "df = df.dropna(subset=['Lemma 1', 'Lemma 2'])\n",
    "df['Bigram'] = df.apply(lambda row: creating_bigram(row['Lemma 1'], row['Lemma 2']), axis=1)\n",
    "df['Phrase'] = df['Часть 1'] + ' ' + df['Часть 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization of expressions and their constituents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load_word2vec_format('ruwikiruscorpora_superbigrams_2_1_2.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization(w):\n",
    "    try:\n",
    "        return wv[w]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_embs = ['Lemma 1', 'Lemma 2', 'Bigram']\n",
    "for col in col_embs:\n",
    "    df['w2v_'+ col] = df[col].apply(lambda w: vectorization(w))\n",
    "w2v_df = df.dropna(subset=['w2v_Lemma 1', 'w2v_Lemma 2', 'w2v_Bigram']) # ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating of cosine similarities between vectors of expressions and their constituents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_df['w2v_sim_1'] = w2v_df.apply(lambda row: 1 - distance.cosine(row['w2v_Lemma 1'], row['w2v_Bigram']),                           \n",
    "                                   axis=1)\n",
    "w2v_df['w2v_sim_2'] = w2v_df.apply(lambda row: 1 - distance.cosine(row['w2v_Lemma 2'], row['w2v_Bigram']), \n",
    "                                   axis=1)\n",
    "df = pd.concat([df, w2v_df[['w2v_sim_1', 'w2v_sim_2']]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating of the frequency dictionary from RNC (https://ruscorpora.ru/new/corpora-freq.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6750525/6750525 [02:58<00:00, 37887.03it/s]\n"
     ]
    }
   ],
   "source": [
    "def freq_dict(): \n",
    "    with open('2grams-3.txt') as fh:\n",
    "        bigrams = fh.readlines()\n",
    "\n",
    "    main_dict = {}\n",
    "    for bi in tqdm(bigrams):\n",
    "        bigr = bi.strip('\\n').split('\\t')\n",
    "        if bigr[2] != '':\n",
    "            continue\n",
    "        lemma1 = analysis(bigr[1], 'ADJF')\n",
    "        if type(lemma1) == float:\n",
    "            continue\n",
    "        lemma2 = analysis(bigr[3], 'NOUN')\n",
    "        if type(lemma2) == float:\n",
    "            continue\n",
    "        bigram = creating_bigram(lemma1, lemma2)\n",
    "        main_dict[bigram] = int(bigr[0])\n",
    "        return main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dict = freq_dict()\n",
    "main_dict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = min(main_dict.values())\n",
    "ma = max(main_dict.values())\n",
    "df['Frequency_norm'] = df['Bigram'].apply(lambda k: (main_dict[k] - mi) / (ma - mi)\\\n",
    "    if k in main_dict else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('main_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitution of expressions' constituents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masking each of constituents in contexts -> 2 variants for each context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def masking(phrase, context):\n",
    "    phrase_tokens = word_tokenize(phrase)\n",
    "    context_tokens = word_tokenize(context)\n",
    "    context_tokens_2 = copy.deepcopy(context_tokens)\n",
    "    phrase_lemmas = [m.parse(w)[0].normal_form for w in phrase_tokens]\n",
    "    context_lemmas = [m.parse(w.lower())[0].normal_form for w in context_tokens]\n",
    "    if phrase_lemmas[0] in context_lemmas and phrase_lemmas[1] in context_lemmas:\n",
    "        context_tokens[context_lemmas.index(phrase_lemmas[0])] = '<mask>'\n",
    "        context_tokens_2[context_lemmas.index(phrase_lemmas[1])] = '<mask>'\n",
    "    else:\n",
    "        return np.nan, np.nan\n",
    "    result1 = ' '.join(context_tokens)\n",
    "    result2 = ' '.join(context_tokens_2)\n",
    "    return result1, result2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked = df.apply(lambda row: masking(row['Phrase'], row['Контекст 1']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, masked], axis=1)\n",
    "df = df.rename(columns={0:'Masked'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Left_masked'] = df['Masked'].apply(lambda k: k[0])\n",
    "df['Right_masked'] = df['Masked'].apply(lambda k: k[1])\n",
    "df = df.drop(columns=['Masked'])\n",
    "df = df.dropna(subset=['Left_masked', 'Right_masked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitution via `sberbank-ai/ruRoberta-large`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/ruRoberta-large\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"sberbank-ai/ruRoberta-large\")\n",
    "nlp_fill = FillMaskPipeline(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitution(word, context):\n",
    "    if context == np.nan:\n",
    "        return np.nan\n",
    "    substs = nlp_fill(context, top_k=5)\n",
    "    substs_str = [s['token_str'].strip() for s in substs]\n",
    "    for s in substs_str:\n",
    "        if m.parse(s)[0].normal_form == m.parse(word[0])[0].normal_form:\n",
    "            continue\n",
    "    else:\n",
    "        return context.replace('<mask>', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Left_var'] = df.apply(lambda row: substitution(row['Часть 1'], row['Left_masked']), axis=1)\n",
    "df['Right_var'] = df.apply(lambda row: substitution(row['Часть 2'], row['Right_masked']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Sentence Encoder (USE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting values that shoud be vectorized by USE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_use = df[['Часть 1', 'Часть 2', 'Phrase', 'Контекст 1', 'Left_var', 'Right_var']].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_for_use = []\n",
    "for f in tqdm(for_use_sub):\n",
    "    all_for_use.extend(list(f.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing via `google/universal-sentence-encoder-multilingual-large/2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/2')\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    embeddings = session.run(embed(all_for_use))['outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_from_use = []\n",
    "embeddings = list(embeddings)\n",
    "for i in range(0, len(embeddings), 6):\n",
    "    use_dict = {}\n",
    "    use_dict['USE_Часть 1'] = embeddings[i]\n",
    "    use_dict['USE_Часть 2'] = embeddings[i+1]\n",
    "    use_dict['USE_Phrase'] = embeddings[i+2]\n",
    "    use_dict['USE_Контекст 1'] = embeddings[i+3]\n",
    "    use_dict['USE_Left_var'] = embeddings[i+4]\n",
    "    use_dict['USE_Right_var'] = embeddings[i+5]\n",
    "    embs_from_use.append(use_dict)\n",
    "use_df = pd.DataFrame(embs_from_use)\n",
    "df = pd.concat([df, use_df], axis=1)\n",
    "df.to_csv('main_dataset_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('main_dataset_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter(vec_str):\n",
    "    if type(vec_str) != float:\n",
    "        vec_str = vec_str.strip('[ ')\n",
    "        vec_str = vec_str.strip('] ')\n",
    "        return np.array([float(n) for n in vec_str.split()])\n",
    "    else:\n",
    "        return vec_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    if c.startswith('USE') or c.startswith('w2v_L') or c.startswith('w2v_B'):\n",
    "        df[c] = df[c].apply(lambda k: converter(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating of missing cosine similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['USE_sim_1'] = df.apply(lambda row: 1 - distance.cosine(row['USE_Часть 1'], row['USE_Phrase']), axis=1)\n",
    "df['USE_sim_2'] = df.apply(lambda row: 1 - distance.cosine(row['USE_Часть 2'], row['USE_Phrase']), axis=1)\n",
    "df['USE+BERT_sim_1'] = df.apply(lambda row: 1 - distance.cosine(row['USE_Left_var'], row['USE_Контекст 1']), axis=1)\n",
    "df['USE+BERT_sim_2'] = df.apply(lambda row: 1 - distance.cosine(row['USE_Right_var'], row['USE_Контекст 1']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[df['Композициональность'] < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_w2v_sim = new_df.dropna().loc[:, ['w2v_sim_1', 'w2v_sim_2']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_use_sim = new_df.dropna().loc[:, ['USE_sim_1','USE_sim_2']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_feats(embeddings):\n",
    "    feats_new = []\n",
    "    for f in embeddings:\n",
    "        lst = []\n",
    "        for fe in f:\n",
    "            if type(fe) == str:\n",
    "                lst.append(fe)\n",
    "            else:\n",
    "                try:\n",
    "                    lst.extend(fe)\n",
    "                except:\n",
    "                    lst.append(fe)\n",
    "        feats_new.append(lst)\n",
    "    return feats_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_w2v = embeddings_feats(new_df.dropna().loc[:, ['w2v_Lemma 1', \n",
    "                                                     'w2v_Lemma 2', \n",
    "                                                     'w2v_Bigram']].values.tolist())\n",
    "\n",
    "feats_use = embeddings_feats(new_df.dropna().loc[:, ['USE_Часть 1', 'USE_Часть 2', \n",
    "                                            'USE_Phrase', 'USE_Контекст 1']].values.tolist())\n",
    "\n",
    "feats_use_wo_context = embeddings_feats(new_df.dropna().loc[:, ['USE_Часть 1', \n",
    "                                                       'USE_Часть 2', \n",
    "                                                       'USE_Phrase']].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_w2v = new_df.dropna()['Композициональность'].values.tolist()\n",
    "targets_use = new_df.dropna()['Композициональность'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for using ML: `train_test_split`, initializing of ML method, fitting, calcucating classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data, targets, fi=False):  \n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, targets, \n",
    "                                                        test_size=0.15, random_state=3)\n",
    "    train_words, train_x = get_words(train_x)\n",
    "    test_words, test_x = get_words(test_x)\n",
    "    tree = DecisionTreeClassifier(random_state=0)\n",
    "    tree.fit(train_x, train_y)\n",
    "    print(classification_report(test_y, tree.predict(test_x)))\n",
    "    if fi:\n",
    "        feat_imps = tree.feature_importances_\n",
    "        for i in range(4):\n",
    "            print(sum(feat_imps[int(len(feat_imps) / 4 * i):int(len(feat_imps) / 4 * (i + 1))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features: cosine similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS: Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.67      0.64        24\n",
      "         1.0       0.70      0.66      0.68        29\n",
      "\n",
      "    accuracy                           0.66        53\n",
      "   macro avg       0.66      0.66      0.66        53\n",
      "weighted avg       0.66      0.66      0.66        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify(feats_w2v_sim, targets_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS: USE embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.46      0.42        24\n",
      "         1.0       0.46      0.38      0.42        29\n",
      "\n",
      "    accuracy                           0.42        53\n",
      "   macro avg       0.42      0.42      0.42        53\n",
      "weighted avg       0.42      0.42      0.42        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify(feats_use_sim, targets_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features: embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.88      0.81        24\n",
      "         1.0       0.88      0.76      0.81        29\n",
      "\n",
      "    accuracy                           0.81        53\n",
      "   macro avg       0.81      0.82      0.81        53\n",
      "weighted avg       0.82      0.81      0.81        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify(feats_w2v, targets_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE embeddings with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.83      0.83        24\n",
      "         1.0       0.86      0.86      0.86        29\n",
      "\n",
      "    accuracy                           0.85        53\n",
      "   macro avg       0.85      0.85      0.85        53\n",
      "weighted avg       0.85      0.85      0.85        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify(feats_use, targets_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE embeddings without context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.75      0.73        24\n",
      "         1.0       0.79      0.76      0.77        29\n",
      "\n",
      "    accuracy                           0.75        53\n",
      "   macro avg       0.75      0.75      0.75        53\n",
      "weighted avg       0.76      0.75      0.76        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify(feats_use_wo_context, targets_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS: Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.22 MAE: 0.45\n"
     ]
    }
   ],
   "source": [
    "clf = LinearRegression(positive=True)\n",
    "clf.fit(feats_w2v_sim, targets_w2v)\n",
    "print('MSE:', round(mean_squared_error(targets_w2v, clf.predict(feats_w2v_sim)), 2), \n",
    "      'MAE:', round(mean_absolute_error(targets_w2v, clf.predict(feats_w2v_sim)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = new_df.dropna()['Phrase'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table with scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.993950</td>\n",
       "      <td>апелляционная инстанция</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.973234</td>\n",
       "      <td>акционерное общество</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.935329</td>\n",
       "      <td>арбузная корка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.932819</td>\n",
       "      <td>беспилотный аппарат</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.921375</td>\n",
       "      <td>авторитарная власть</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.219837</td>\n",
       "      <td>мировая судья</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.205752</td>\n",
       "      <td>бархатная революция</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.193058</td>\n",
       "      <td>открытое письмо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.172262</td>\n",
       "      <td>оранжевая революция</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.030798</td>\n",
       "      <td>заднее число</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                   Phrase\n",
       "276  0.993950  апелляционная инстанция\n",
       "226  0.973234     акционерное общество\n",
       "283  0.935329           арбузная корка\n",
       "320  0.932819      беспилотный аппарат\n",
       "186  0.921375      авторитарная власть\n",
       "..        ...                      ...\n",
       "80   0.219837            мировая судья\n",
       "2    0.205752      бархатная революция\n",
       "105  0.193058          открытое письмо\n",
       "97   0.172262      оранжевая революция\n",
       "46   0.030798             заднее число\n",
       "\n",
       "[351 rows x 2 columns]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = pd.concat([pd.Series(clf.predict(feats_w2v_sim)), \n",
    "           phrases], axis=1).sort_values(by=[0], ascending=False)\n",
    "lr[lr[0] < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.to_csv('lr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS: USE embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.24 MAE: 0.49\n"
     ]
    }
   ],
   "source": [
    "clf2 = LinearRegression(positive=True)\n",
    "clf2.fit(feats_use_sim, targets_use)\n",
    "print('MSE:', round(mean_squared_error(targets_use, clf2.predict(feats_use_sim)), 2), \n",
    "      'MAE:', round( mean_absolute_error(targets_use, clf2.predict(feats_use_sim)), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE embeddings with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI: 0.14553640780295107\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=3).fit(feats_use)\n",
    "labels = kmeans.labels_\n",
    "print('ARI:', adjusted_rand_score(targets_use, labels))\n",
    "phrases2 = new_df['Phrase']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0                           Phrase    1\n",
      "0    0.0           абсолютное большинство  0.0\n",
      "141  0.0                      первая леди  0.0\n",
      "142  0.0                     первое время  0.0\n",
      "144  0.0                     первый канал  0.0\n",
      "145  0.0                переходный период  0.0\n",
      "146  0.0                переходный металл  0.0\n",
      "147  0.0                 пограничный слой  0.0\n",
      "148  0.0                политическая сила  0.0\n",
      "149  0.0                   полная катушка  0.0\n",
      "150  0.0                    почтовый ящик  0.0\n",
      "140  0.0                  пенсионный фонд  0.0\n",
      "151  0.0                      правый рука  0.0\n",
      "155  0.0             промышленный шпионаж  0.0\n",
      "158  0.0                пулемётная трасса  0.0\n",
      "159  0.0                     рабочая сила  0.0\n",
      "160  0.0                   разная область  0.0\n",
      "161  0.0                   реальное время  0.0\n",
      "162  0.0                  римская империя  0.0\n",
      "163  0.0                     римский папа  0.0\n",
      "164  0.0               российская сторона  0.0\n",
      "165  0.0                российская газета  0.0\n",
      "154  0.0           промышленная революция  0.0\n",
      "139  0.0          партийное строительство  0.0\n",
      "136  0.0                    открытое море  0.0\n",
      "133  0.0                    острый вопрос  0.0\n",
      "100  0.0                     львиная доля  0.0\n",
      "101  0.0                   магнитная буря  0.0\n",
      "102  0.0                массовый характер  0.0\n",
      "103  0.0               медицинская сестра  0.0\n",
      "104  0.0              международный арена  0.0\n",
      "105  0.0                    мировая судья  0.0\n",
      "106  0.0                  мобильная связь  0.0\n",
      "109  0.0                 налоговый кодекс  0.0\n",
      "110  0.0                   насыщенный пар  0.0\n",
      "111  0.0             натуральная величина  0.0\n",
      "113  0.0               невооруженный глаз  0.0\n",
      "114  0.0                 нефтяной картель  0.0\n",
      "115  0.0                     новая газета  0.0\n",
      "116  0.0                      новая волна  0.0\n",
      "117  0.0                        новый тип  0.0\n",
      "120  0.0                      общая черта  0.0\n",
      "122  0.0                  огненная трасса  0.0\n",
      "123  0.0                окладистая борода  0.0\n",
      "130  0.0           острая недостаточность  0.0\n",
      "131  0.0                  острое ощущение  0.0\n",
      "132  0.0                   острый дефицит  0.0\n",
      "167  0.0                      русский дом  0.0\n",
      "99   0.0                 лунная программа  0.0\n",
      "169  0.0                  светлое будущее  0.0\n",
      "171  0.0                сердечный приступ  1.0\n",
      "312  0.0          американский специалист  1.0\n",
      "313  0.0               американский физик  1.0\n",
      "314  0.0           американский экономист  1.0\n",
      "315  0.0            американский дипломат  1.0\n",
      "316  0.0                американский врач  1.0\n",
      "317  0.0            американский художник  1.0\n",
      "318  0.0       американское правительство  1.0\n",
      "319  0.0            американское общество  1.0\n",
      "320  0.0         американское предприятие  1.0\n",
      "311  0.0              американский индеец  1.0\n",
      "334  0.0            антивирусная компания  1.0\n",
      "340  0.0                 апельсиновый сок  1.0\n",
      "341  0.0                  арабская страна  1.0\n",
      "342  0.0                   арабские цифры  1.0\n",
      "343  0.0                     арабский мир  1.0\n",
      "344  0.0             арабское государство  1.0\n",
      "345  0.0                  арбитражный суд  1.0\n",
      "347  0.0          арифметическое действие  1.0\n",
      "349  0.0            армянское предприятие  1.0\n",
      "350  0.0            артериальное давление  1.0\n",
      "335  0.0           антимонопольная служба  1.0\n",
      "309  0.0       американский исследователь  1.0\n",
      "308  0.0             американский военный  1.0\n",
      "300  0.0              американская газета  1.0\n",
      "174  0.0                   сибирская язва  1.0\n",
      "351  0.0       артикуляционное упражнение  1.0\n",
      "180  0.0                  солнечное пятно  1.0\n",
      "182  0.0                    сотовая связь  1.0\n",
      "194  0.0                   торговая война  1.0\n",
      "195  0.0                     торговый дом  1.0\n",
      "205  0.0                   холодная война  1.0\n",
      "211  0.0                     чёрный рынок  1.0\n",
      "233  0.0             автомобильная пробка  1.0\n",
      "266  0.0                  активная работа  1.0\n",
      "267  0.0                   активная форма  1.0\n",
      "268  0.0               активная поддержка  1.0\n",
      "273  0.0               активное население  1.0\n",
      "277  0.0              актуальная проблема  1.0\n",
      "283  0.0                 альпийский стиль  1.0\n",
      "286  0.0           альтернативное видение  1.0\n",
      "287  0.0            альтернативное зрение  1.0\n",
      "288  0.0          альтернативный источник  1.0\n",
      "289  0.0                алюминиевый завод  1.0\n",
      "290  0.0                 амбициозная цель  1.0\n",
      "292  0.0             американская авиация  1.0\n",
      "170  0.0                священная империя  1.0\n",
      "98   0.0                    личный состав  0.0\n",
      "352  0.0            артиллерийский снаряд  1.0\n",
      "96   0.0                ледниковый период  0.0\n",
      "55   0.0                      детский сад  0.0\n",
      "57   0.0                   длинный кредит  0.0\n",
      "30   0.0          временная администрация  0.0\n",
      "29   0.0                   воронья пещера  0.0\n",
      "28   0.0                   волновой поток  0.0\n",
      "61   0.0                    дохлая лошадь  0.0\n",
      "62   0.0                  железная дорога  0.0\n",
      "63   0.0                 железный занавес  0.0\n",
      "64   0.0                    живое общение  0.0\n",
      "65   0.0                       живой язык  0.0\n",
      "67   0.0                 заёмные средства  0.0\n",
      "26   0.0                  воздушная масса  0.0\n",
      "68   0.0                 здоровый человек  0.0\n",
      "69   0.0                       земной шар  0.0\n",
      "70   0.0                    золотой запас  0.0\n",
      "54   0.0                      детский дом  0.0\n",
      "25   0.0                 военная операция  0.0\n",
      "53   0.0                    движущая сила  0.0\n",
      "51   0.0                   грязные деньги  0.0\n",
      "37   0.0                     главная роль  0.0\n",
      "38   0.0                  главный инженер  0.0\n",
      "39   0.0                    главный герой  0.0\n",
      "40   0.0                   глазное яблоко  0.0\n",
      "41   0.0               глубокая древность  0.0\n",
      "42   0.0              голландская болезнь  0.0\n",
      "43   0.0                 голодный экспорт  0.0\n",
      "44   0.0                    голодный бунт  0.0\n",
      "34   0.0                     высокая мода  0.0\n",
      "45   0.0                   гоночная серия  0.0\n",
      "46   0.0                  горячая десятка  0.0\n",
      "47   0.0          государственный экзамен  0.0\n",
      "48   0.0              государственный муж  0.0\n",
      "49   0.0                 гражданская сила  0.0\n",
      "50   0.0                 грубое нарушение  0.0\n",
      "52   0.0              гуманитарная помощь  0.0\n",
      "72   0.0                  золотой мальчик  0.0\n",
      "97   0.0                   личная свобода  0.0\n",
      "24   0.0               властная вертикаль  0.0\n",
      "81   0.0             королевский институт  0.0\n",
      "82   0.0                     костный мозг  0.0\n",
      "83   0.0                   крайний случай  0.0\n",
      "9    0.0                  большая пятерка  0.0\n",
      "7    0.0                       битое поле  0.0\n",
      "85   0.0                  красная планета  0.0\n",
      "86   0.0                    красная черта  0.0\n",
      "6    0.0                   бешеные деньги  0.0\n",
      "5    0.0                   бездонный глаз  0.0\n",
      "88   0.0                     красное море  0.0\n",
      "89   0.0                 крепостное право  0.0\n",
      "90   0.0                     круглый стол  0.0\n",
      "91   0.0                  круговая порука  0.0\n",
      "92   0.0                  кубический метр  0.0\n",
      "93   0.0              кубический километр  0.0\n",
      "2    0.0              аналитическая химия  0.0\n",
      "95   0.0                  лёгкая атлетика  0.0\n",
      "10   0.0                   большая деньги  0.0\n",
      "11   0.0                 большая четверка  0.0\n",
      "3    0.0              бархатная революция  0.0\n",
      "14   0.0                    бронзовый век  0.0\n",
      "75   0.0                     каменный век  0.0\n",
      "21   0.0                великое множество  0.0\n",
      "73   0.0                    золотой дождь  0.0\n",
      "12   0.0                большая восьмерка  0.0\n",
      "13   0.0                 большое значение  0.0\n",
      "78   0.0                  квадратный метр  0.0\n",
      "77   0.0             католическая церковь  0.0\n",
      "76   0.0               карьерная лестница  0.0\n",
      "20   0.0                     великий пост  0.0\n",
      "19   0.0                   великая хартия  0.0\n",
      "17   0.0                   вдовий пароход  0.0\n",
      "18   0.0                великая революция  0.0\n",
      "244  1.0            агитационный материал  1.0\n",
      "279  1.0             акционерное общество  1.0\n",
      "246  1.0                агрессивная среда  1.0\n",
      "247  1.0            агрессивное поведение  1.0\n",
      "248  1.0         административная реформа  1.0\n",
      "301  1.0              американская помощь  1.0\n",
      "245  1.0                  аграрный вопрос  1.0\n",
      "243  1.0          авторское свидетельство  1.0\n",
      "239  1.0               авторитарный режим  1.0\n",
      "241  1.0              авторитетный журнал  1.0\n",
      "240  1.0         авторитетная организация  1.0\n",
      "249  1.0         административная система  1.0\n",
      "238  1.0        авторитарная модернизация  1.0\n",
      "237  1.0              авторитарная власть  1.0\n",
      "236  1.0                 автономный робот  1.0\n",
      "235  1.0            автономное сообщество  1.0\n",
      "295  1.0             американская коллега  1.0\n",
      "296  1.0           американская экономика  1.0\n",
      "229  1.0             автоматическая линия  1.0\n",
      "242  1.0                  авторское право  1.0\n",
      "250  1.0          административная власть  1.0\n",
      "256  1.0           административный орган  1.0\n",
      "252  1.0        административное давление  1.0\n",
      "281  1.0                   алтайский край  1.0\n",
      "278  1.0                актуальный вопрос  1.0\n",
      "285  1.0             альтернативная форма  1.0\n",
      "339  1.0          апелляционная инстанция  1.0\n",
      "272  1.0                активное вещество  1.0\n",
      "271  1.0                активное действие  1.0\n",
      "270  1.0                 активное участие  1.0\n",
      "269  1.0                    активная роль  1.0\n",
      "27   1.0                  воздушный мешок  0.0\n",
      "297  1.0               американская армия  1.0\n",
      "263  1.0             академическое звание  1.0\n",
      "262  1.0           академический институт  1.0\n",
      "261  1.0          академическая программа  1.0\n",
      "260  1.0              академическая среда  1.0\n",
      "259  1.0                 азиатская страна  1.0\n",
      "258  1.0                    азартная игра  1.0\n",
      "257  1.0               адронный коллайдер  1.0\n",
      "228  1.0           автоматическая станция  1.0\n",
      "255  1.0           административный метод  1.0\n",
      "254  1.0          административный ресурс  1.0\n",
      "253  1.0           административный центр  1.0\n",
      "251  1.0         административное деление  1.0\n",
      "280  1.0            алкогольная продукция  1.0\n",
      "176  1.0             следственный комитет  1.0\n",
      "124  1.0            октябрьская революция  0.0\n",
      "125  1.0                   оловянная чума  0.0\n",
      "126  1.0              оранжевая революция  0.0\n",
      "127  1.0                     особое место  0.0\n",
      "128  1.0                  острая проблема  0.0\n",
      "129  1.0                  острая нехватка  0.0\n",
      "206  1.0                      худой конец  1.0\n",
      "138  1.0                  открытый воздух  0.0\n",
      "135  1.0                    открытое небо  0.0\n",
      "306  2.0           американский президент  1.0\n",
      "307  2.0              американский ученый  1.0\n",
      "22   2.0                  вечная мерзлота  0.0\n",
      "305  2.0              американские войска  1.0\n",
      "310  2.0            американский психолог  1.0\n",
      "16   2.0                 бюджетный кодекс  0.0\n",
      "23   2.0                  взлётная полоса  0.0\n",
      "304  2.0              американская валюта  1.0\n",
      "217  2.0                 энное количество  1.0\n",
      "15   2.0                    бросовая цена  0.0\n",
      "74   2.0                      золотой век  0.0\n",
      "134  2.0                 отбойный молоток  0.0\n",
      "299  2.0               американская фирма  1.0\n",
      "298  2.0            американская разведка  1.0\n",
      "137  2.0                  открытое письмо  0.0\n",
      "294  2.0             американская сторона  1.0\n",
      "293  2.0              американская власть  1.0\n",
      "71   2.0                 золотой миллиард  0.0\n",
      "291  2.0            американская компания  1.0\n",
      "143  2.0                       первый тур  0.0\n",
      "66   2.0                     заднее число  0.0\n",
      "60   2.0               домашний кинотеатр  0.0\n",
      "152  2.0               преклонный возраст  0.0\n",
      "303  2.0        американская телекомпания  1.0\n",
      "302  2.0          американская спецслужба  1.0\n",
      "121  2.0              общественная палата  0.0\n",
      "79   2.0                  ключевой вопрос  0.0\n",
      "1    2.0                акустическое окно  0.0\n",
      "94   2.0                   культурный код  0.0\n",
      "348  2.0                  армянский народ  1.0\n",
      "107  2.0                   мысленный взор  0.0\n",
      "346  2.0                   арбузная корка  1.0\n",
      "4    2.0             басманное правосудие  0.0\n",
      "108  2.0                   мягкая посадка  0.0\n",
      "87   2.0                   красная звезда  0.0\n",
      "112  2.0                    научная мысль  0.0\n",
      "8    2.0                 боевое искусство  0.0\n",
      "84   2.0                    красная армия  0.0\n",
      "80   2.0             комсомольский правда  0.0\n",
      "338  2.0  антропологическая реконструкция  1.0\n",
      "337  2.0    антитеррористическая операция  1.0\n",
      "153  2.0                  приборная доска  0.0\n",
      "336  2.0    антитеррористическая коалиция  1.0\n",
      "119  2.0                     ночной дозор  0.0\n",
      "333  2.0                 анонимный звонок  1.0\n",
      "332  2.0               английский перевод  1.0\n",
      "331  2.0                 английский текст  1.0\n",
      "330  2.0                английский король  1.0\n",
      "329  2.0                английский ученый  1.0\n",
      "328  2.0                  английский язык  1.0\n",
      "327  2.0               аналогичный прибор  1.0\n",
      "326  2.0               аналогичный период  1.0\n",
      "325  2.0           аналогичный показатель  1.0\n",
      "324  2.0             аналогичная ситуация  1.0\n",
      "323  2.0              аналитический отдел  1.0\n",
      "322  2.0              аналитический центр  1.0\n",
      "321  2.0                 амурская область  1.0\n",
      "118  2.0                     новый взгляд  0.0\n",
      "59   2.0                  добрая половина  0.0\n",
      "284  2.0            альтернативная служба  1.0\n",
      "31   2.0                всемирная паутина  0.0\n",
      "196  2.0                     точная наука  1.0\n",
      "197  2.0                   третья колонна  1.0\n",
      "198  2.0                 уголовный кодекс  1.0\n",
      "199  2.0                    ударная волна  1.0\n",
      "200  2.0                       узкий круг  1.0\n",
      "201  2.0                   учёная степень  1.0\n",
      "202  2.0                   фантомная боль  1.0\n",
      "203  2.0                федеральный орган  1.0\n",
      "204  2.0              финансовая пирамида  1.0\n",
      "207  2.0                   цепная реакция  1.0\n",
      "208  2.0                      черная дыра  1.0\n",
      "209  2.0                    черное золото  1.0\n",
      "210  2.0                    черный молния  1.0\n",
      "234  2.0            автономное учреждение  1.0\n",
      "193  2.0                   тёмная материя  1.0\n",
      "212  2.0                      чёрный пиар  1.0\n",
      "231  2.0             автомобильная дорога  1.0\n",
      "230  2.0            автоматическое оружие  1.0\n",
      "213  2.0                  широкая публика  1.0\n",
      "214  2.0                     широкий круг  1.0\n",
      "227  2.0             австралийский доллар  1.0\n",
      "226  2.0             авиационный институт  1.0\n",
      "215  2.0                электронная почта  1.0\n",
      "224  2.0            авиационная федерация  1.0\n",
      "223  2.0       авиационная промышленность  1.0\n",
      "222  2.0               аварийная ситуация  1.0\n",
      "221  2.0               абсолютный чемпион  1.0\n",
      "220  2.0                    яркий человек  1.0\n",
      "219  2.0                 юридическое лицо  1.0\n",
      "218  2.0                этнический маркер  1.0\n",
      "232  2.0     автомобильная промышленность  1.0\n",
      "216  2.0             элементарная частица  1.0\n",
      "192  2.0                   счётная палата  1.0\n",
      "190  2.0                 стволовая клетка  1.0\n",
      "282  2.0                  альпийские лыжи  1.0\n",
      "58   2.0                      добрая воля  0.0\n",
      "156  2.0                     прямая линия  0.0\n",
      "157  2.0               пулемётная очередь  0.0\n",
      "56   2.0                   длинные деньги  0.0\n",
      "32   2.0                 второй секретарь  0.0\n",
      "276  2.0                   активный отдых  1.0\n",
      "275  2.0               активный сторонник  1.0\n",
      "274  2.0                активный участник  1.0\n",
      "33   2.0                      второй план  0.0\n",
      "166  2.0                 российский рынок  0.0\n",
      "168  2.0                     самый разгар  0.0\n",
      "172  2.0                серебряный призер  1.0\n",
      "173  2.0                сетевая структура  1.0\n",
      "191  2.0                  столетняя война  1.0\n",
      "175  2.0                     слабое звено  1.0\n",
      "36   2.0                     высший орган  0.0\n",
      "265  2.0            активная деятельность  1.0\n",
      "264  2.0           аккумуляторная батарея  1.0\n",
      "177  2.0                   советский союз  1.0\n",
      "178  2.0                     солёный вода  1.0\n",
      "179  2.0                 солнечная корона  1.0\n",
      "181  2.0                   солнечный диск  1.0\n",
      "183  2.0                  социальная сеть  1.0\n",
      "184  2.0                     спинной мозг  1.0\n",
      "185  2.0                 средиземное море  1.0\n",
      "186  2.0                     средние века  1.0\n",
      "187  2.0                    средний класс  1.0\n",
      "188  2.0                  средний уровень  1.0\n",
      "189  2.0                     средняя рука  1.0\n",
      "35   2.0                 высокое качество  0.0\n",
      "225  2.0                авиационная бомба  1.0\n",
      "353  NaN             астрономическое окно  NaN\n",
      "354  NaN              атлантический океан  NaN\n",
      "355  NaN                атмосферный фронт  NaN\n",
      "356  NaN               атмосферный воздух  NaN\n",
      "357  NaN           атомная электростанция  NaN\n",
      "358  NaN                    атомная бомба  NaN\n",
      "359  NaN               атомная энергетика  NaN\n",
      "360  NaN           атомная промышленность  NaN\n",
      "361  NaN          аттестационная комиссия  NaN\n",
      "362  NaN           аттосекундный диапазон  NaN\n",
      "363  NaN                афганская граница  NaN\n",
      "364  NaN                афганская столица  NaN\n",
      "365  NaN              афганская провинция  NaN\n",
      "366  NaN          афганское правительство  NaN\n",
      "367  NaN                  базовый элемент  NaN\n",
      "368  NaN                    базовый навык  NaN\n",
      "369  NaN             байкальский комбинат  NaN\n",
      "370  NaN                 балканская война  NaN\n",
      "371  NaN                  балтийский флот  NaN\n",
      "372  NaN               банковская система  NaN\n",
      "373  NaN                 банковская тайна  NaN\n",
      "374  NaN                  банковский счет  NaN\n",
      "375  NaN                банковский сектор  NaN\n",
      "376  NaN                банковский кредит  NaN\n",
      "377  NaN                  банковское дело  NaN\n",
      "378  NaN                   баренцево море  NaN\n",
      "379  NaN             баскетбольный тренер  NaN\n",
      "380  NaN                      бедная руда  NaN\n",
      "381  NaN                  бедренная кость  NaN\n",
      "382  NaN            бедственное положение  NaN\n",
      "383  NaN           безотходная технология  NaN\n",
      "384  NaN                     белая фигура  NaN\n",
      "385  NaN                       белая рука  NaN\n",
      "386  NaN                       белый цвет  NaN\n",
      "387  NaN                     белый фермер  NaN\n",
      "388  NaN                    белый человек  NaN\n",
      "389  NaN                  береговая линия  NaN\n",
      "390  NaN               беременная женщина  NaN\n",
      "391  NaN               берестяная грамота  NaN\n",
      "392  NaN                  бесконечный ряд  NaN\n",
      "393  NaN              беспилотный аппарат  NaN\n",
      "394  NaN                бесплатная услуга  NaN\n",
      "395  NaN           бесплатное образование  NaN\n",
      "396  NaN                бесплатный сервис  NaN\n",
      "397  NaN              бесчисленный остров  NaN\n",
      "398  NaN            биогеохимический цикл  NaN\n",
      "399  NaN            биологическая система  NaN\n",
      "400  NaN              биологическая наука  NaN\n",
      "401  NaN           биологическая проблема  NaN\n",
      "402  NaN           биологическая мембрана  NaN\n",
      "403  NaN            биологический возраст  NaN\n",
      "404  NaN               биологический ритм  NaN\n",
      "405  NaN              биологический закон  NaN\n",
      "406  NaN           биологический материал  NaN\n",
      "407  NaN             биологический объект  NaN\n",
      "408  NaN             биологическое оружие  NaN\n",
      "409  NaN                      благая цель  NaN\n",
      "410  NaN          благодарственная оплата  NaN\n",
      "411  NaN            благоприятное условие  NaN\n",
      "412  NaN    благотворительная организация  NaN\n",
      "413  NaN           благотворительная цель  NaN\n",
      "414  NaN           благотворительный фонд  NaN\n",
      "415  NaN                ближайшая станция  NaN\n",
      "416  NaN                  ближайшее время  NaN\n",
      "417  NaN                ближайшее будущее  NaN\n",
      "418  NaN                    ближайший год  NaN\n",
      "419  NaN                  ближайший месяц  NaN\n",
      "420  NaN               ближайший соратник  NaN\n",
      "421  NaN         ближневосточный конфликт  NaN\n",
      "422  NaN                ближнее зарубежье  NaN\n",
      "423  NaN                  близкая очередь  NaN\n",
      "424  NaN                     близкий друг  NaN\n",
      "425  NaN                 близкий источник  NaN\n",
      "426  NaN                близлежащий пункт  NaN\n",
      "427  NaN                  блокадная книга  NaN\n",
      "428  NaN                бобслейная трасса  NaN\n",
      "429  NaN                   богатая страна  NaN\n",
      "430  NaN                  богатый человек  NaN\n",
      "431  NaN                     богатый опыт  NaN\n",
      "432  NaN                    богатый купец  NaN\n",
      "433  NaN         богословское образование  NaN\n",
      "434  NaN                   боевой корабль  NaN\n",
      "435  NaN                   боевые заслуги  NaN\n",
      "436  NaN                    большая часть  NaN\n",
      "437  NaN                     большая роль  NaN\n",
      "438  NaN                 большая проблема  NaN\n",
      "439  NaN                   большая потеря  NaN\n"
     ]
    }
   ],
   "source": [
    "cl = pd.concat([pd.Series(labels), pd.Series(phrases2), pd.Series(targets_use)], axis=1)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(cl.sort_values(by=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
