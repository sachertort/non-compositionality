{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Композициональность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports of all neccessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from gensim.models import KeyedVectors\n",
    "from scipy.spatial import distance\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# import tensorflow_text\n",
    "from nltk import word_tokenize\n",
    "import copy\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import FillMaskPipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('compounds_AN_top10000.csv')\n",
    "df = df.drop(labels=['Unnamed: 0'], axis=1)\n",
    "df = df.drop(labels=[5593], axis=0)\n",
    "df['Композициональность'] = pd.to_numeric(df['Композициональность'])\n",
    "df = pd.concat([df[df['Композициональность'] == 0], \n",
    "                df[df['Композициональность'] == 1][:248],\n",
    "                df[df['Композициональность'] == 2][:248]])\n",
    "df = df.iloc[:, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization and PoS tagging via `pymorphy2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(word, pos):\n",
    "    variants = m.parse(word.lower())\n",
    "    for var in variants:\n",
    "        if pos in var.tag:\n",
    "            if pos == 'NOUN':\n",
    "                return var.normal_form + '_' + pos\n",
    "            else:\n",
    "                return var.normal_form + '_' + 'ADJ'\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_bigram(lemma1, lemma2):\n",
    "    lemma1 = lemma1.split('_')\n",
    "    lemma2 = lemma2.split('_')\n",
    "    return lemma1[0] + '::' + lemma2[0] + '_' + lemma1[1] + lemma2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Lemma 1'] = df['Часть 1'].apply(lambda x: analysis(x, 'ADJF'))\n",
    "df['Lemma 2'] = df['Часть 2'].apply(lambda x: analysis(x, 'NOUN'))\n",
    "df = df.dropna(subset=['Lemma 1', 'Lemma 2'])\n",
    "df['Bigram'] = df.apply(lambda row: creating_bigram(row['Lemma 1'], row['Lemma 2']), axis=1)\n",
    "df['Phrase'] = df['Часть 1'] + ' ' + df['Часть 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization of expressions and their constituents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load_word2vec_format('ruwikiruscorpora_superbigrams_2_1_2.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization(w):\n",
    "    try:\n",
    "        return wv[w]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_embs = ['Lemma 1', 'Lemma 2', 'Bigram']\n",
    "for col in col_embs:\n",
    "    df['w2v_'+ col] = df[col].apply(lambda w: vectorization(w))\n",
    "w2v_df = df.dropna(subset=['w2v_Lemma 1', 'w2v_Lemma 2', 'w2v_Bigram']) # ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating of cosine similarities between vectors of expressions and their constituents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_df['w2v_sim_1'] = w2v_df.apply(lambda row: 1 - distance.cosine(row['w2v_Lemma 1'], row['w2v_Bigram']),                           \n",
    "                                   axis=1)\n",
    "w2v_df['w2v_sim_2'] = w2v_df.apply(lambda row: 1 - distance.cosine(row['w2v_Lemma 2'], row['w2v_Bigram']), \n",
    "                                   axis=1)\n",
    "df = pd.concat([df, w2v_df[['w2v_sim_1', 'w2v_sim_2']]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating of the frequency dictionary from RNC (https://ruscorpora.ru/new/corpora-freq.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6750525/6750525 [02:58<00:00, 37887.03it/s]\n"
     ]
    }
   ],
   "source": [
    "def freq_dict(): \n",
    "    with open('2grams-3.txt') as fh:\n",
    "        bigrams = fh.readlines()\n",
    "\n",
    "    main_dict = {}\n",
    "    for bi in tqdm(bigrams):\n",
    "        bigr = bi.strip('\\n').split('\\t')\n",
    "        if bigr[2] != '':\n",
    "            continue\n",
    "        lemma1 = analysis(bigr[1], 'ADJF')\n",
    "        if type(lemma1) == float:\n",
    "            continue\n",
    "        lemma2 = analysis(bigr[3], 'NOUN')\n",
    "        if type(lemma2) == float:\n",
    "            continue\n",
    "        bigram = creating_bigram(lemma1, lemma2)\n",
    "        main_dict[bigram] = int(bigr[0])\n",
    "        return main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dict = freq_dict()\n",
    "main_dict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = min(main_dict.values())\n",
    "ma = max(main_dict.values())\n",
    "df['Frequency_norm'] = df['Bigram'].apply(lambda k: (main_dict[k] - mi) / (ma - mi)\\\n",
    "    if k in main_dict else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('main_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitution of expressions' constituents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masking each of constituents in contexts -> 2 variants for each context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def masking(phrase, context):\n",
    "    phrase_tokens = word_tokenize(phrase)\n",
    "    context_tokens = word_tokenize(context)\n",
    "    context_tokens_2 = copy.deepcopy(context_tokens)\n",
    "    phrase_lemmas = [m.parse(w)[0].normal_form for w in phrase_tokens]\n",
    "    context_lemmas = [m.parse(w.lower())[0].normal_form for w in context_tokens]\n",
    "    if phrase_lemmas[0] in context_lemmas and phrase_lemmas[1] in context_lemmas:\n",
    "        context_tokens[context_lemmas.index(phrase_lemmas[0])] = '<mask>'\n",
    "        context_tokens_2[context_lemmas.index(phrase_lemmas[1])] = '<mask>'\n",
    "    else:\n",
    "        return np.nan, np.nan\n",
    "    result1 = ' '.join(context_tokens)\n",
    "    result2 = ' '.join(context_tokens_2)\n",
    "    return result1, result2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked = df.apply(lambda row: masking(row['Phrase'], row['Контекст 1']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, masked], axis=1)\n",
    "df = df.rename(columns={0:'Masked'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Left_masked'] = df['Masked'].apply(lambda k: k[0])\n",
    "df['Right_masked'] = df['Masked'].apply(lambda k: k[1])\n",
    "df = df.drop(columns=['Masked'])\n",
    "df = df.dropna(subset=['Left_masked', 'Right_masked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitution via `sberbank-ai/ruRoberta-large`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/ruRoberta-large\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"sberbank-ai/ruRoberta-large\")\n",
    "nlp_fill = FillMaskPipeline(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitution(word, context):\n",
    "    if context == np.nan:\n",
    "        return np.nan\n",
    "    substs = nlp_fill(context, top_k=5)\n",
    "    substs_str = [s['token_str'].strip() for s in substs]\n",
    "    for s in substs_str:\n",
    "        if m.parse(s)[0].normal_form == m.parse(word[0])[0].normal_form:\n",
    "            continue\n",
    "    else:\n",
    "        return context.replace('<mask>', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Left_var'] = df.apply(lambda row: substitution(row['Часть 1'], row['Left_masked']), axis=1)\n",
    "df['Right_var'] = df.apply(lambda row: substitution(row['Часть 2'], row['Right_masked']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Sentence Encoder (USE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting values that shoud be vectorized by USE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_use = df[['Часть 1', 'Часть 2', 'Phrase', 'Контекст 1', 'Left_var', 'Right_var']].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_for_use = []\n",
    "for f in tqdm(for_use_sub):\n",
    "    all_for_use.extend(list(f.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing via `google/universal-sentence-encoder-multilingual-large/2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/2')\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    embeddings = session.run(embed(all_for_use))['outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_from_use = []\n",
    "embeddings = list(embeddings)\n",
    "for i in range(0, len(embeddings), 6):\n",
    "    use_dict = {}\n",
    "    use_dict['USE_Часть 1'] = embeddings[i]\n",
    "    use_dict['USE_Часть 2'] = embeddings[i+1]\n",
    "    use_dict['USE_Phrase'] = embeddings[i+2]\n",
    "    use_dict['USE_Контекст 1'] = embeddings[i+3]\n",
    "    use_dict['USE_Left_var'] = embeddings[i+4]\n",
    "    use_dict['USE_Right_var'] = embeddings[i+5]\n",
    "    embs_from_use.append(use_dict)\n",
    "use_df = pd.DataFrame(embs_from_use)\n",
    "df = pd.concat([df, use_df], axis=1)\n",
    "df.to_csv('main_dataset_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('main_dataset_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter(vec_str):\n",
    "    if type(vec_str) != float:\n",
    "        vec_str = vec_str.strip('[ ')\n",
    "        vec_str = vec_str.strip('] ')\n",
    "        return np.array([float(n) for n in vec_str.split()])\n",
    "    else:\n",
    "        return vec_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    if c.startswith('USE') or c.startswith('w2v_L') or c.startswith('w2v_B'):\n",
    "        df[c] = df[c].apply(lambda k: converter(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating of missing cosine similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['USE_sim_1'] = df.apply(lambda row: 1 - distance.cosine(row['USE_Часть 1'], row['USE_Phrase']), axis=1)\n",
    "df['USE_sim_2'] = df.apply(lambda row: 1 - distance.cosine(row['USE_Часть 2'], row['USE_Phrase']), axis=1)\n",
    "df['USE+BERT_sim_1'] = df.apply(lambda row: 1 - distance.cosine(row['USE_Left_var'], row['USE_Контекст 1']), axis=1)\n",
    "df['USE+BERT_sim_2'] = df.apply(lambda row: 1 - distance.cosine(row['USE_Right_var'], row['USE_Контекст 1']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[df['Композициональность'] < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_w2v_sim = new_df.dropna().loc[:, ['w2v_sim_1', 'w2v_sim_2']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_use_sim = new_df.dropna().loc[:, ['USE_sim_1','USE_sim_2']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_feats(embeddings):\n",
    "    feats_new = []\n",
    "    for f in embeddings:\n",
    "        lst = []\n",
    "        for fe in f:\n",
    "            if type(fe) == str:\n",
    "                lst.append(fe)\n",
    "            else:\n",
    "                try:\n",
    "                    lst.extend(fe)\n",
    "                except:\n",
    "                    lst.append(fe)\n",
    "        feats_new.append(lst)\n",
    "    return feats_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_w2v = embeddings_feats(new_df.dropna().loc[:, ['w2v_Lemma 1', \n",
    "                                                     'w2v_Lemma 2', \n",
    "                                                     'w2v_Bigram']].values.tolist())\n",
    "\n",
    "feats_use = embeddings_feats(new_df.dropna().loc[:, ['USE_Часть 1', 'USE_Часть 2', \n",
    "                                            'USE_Phrase', 'USE_Контекст 1']].values.tolist())\n",
    "\n",
    "feats_use_wo_context = embeddings_feats(new_df.dropna().loc[:, ['USE_Часть 1', \n",
    "                                                       'USE_Часть 2', \n",
    "                                                       'USE_Phrase']].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_w2v = new_df.dropna()['Композициональность'].values.tolist()\n",
    "targets_use = new_df.dropna()['Композициональность'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for using ML: `train_test_split`, initializing of ML method, fitting, calcucating classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data, targets, fi=False):  \n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, targets, \n",
    "                                                        test_size=0.15, random_state=3)\n",
    "    train_words, train_x = get_words(train_x)\n",
    "    test_words, test_x = get_words(test_x)\n",
    "    tree = DecisionTreeClassifier(random_state=0)\n",
    "    tree.fit(train_x, train_y)\n",
    "    print(classification_report(test_y, tree.predict(test_x)))\n",
    "    if fi:\n",
    "        feat_imps = tree.feature_importances_\n",
    "        for i in range(4):\n",
    "            print(sum(feat_imps[int(len(feat_imps) / 4 * i):int(len(feat_imps) / 4 * (i + 1))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features: cosine similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS: Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.67      0.64        24\n",
      "         1.0       0.70      0.66      0.68        29\n",
      "\n",
      "    accuracy                           0.66        53\n",
      "   macro avg       0.66      0.66      0.66        53\n",
      "weighted avg       0.66      0.66      0.66        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify(feats_w2v_sim, targets_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS: USE embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.46      0.42        24\n",
      "         1.0       0.46      0.38      0.42        29\n",
      "\n",
      "    accuracy                           0.42        53\n",
      "   macro avg       0.42      0.42      0.42        53\n",
      "weighted avg       0.42      0.42      0.42        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify(feats_use_sim, targets_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features: embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.88      0.81        24\n",
      "         1.0       0.88      0.76      0.81        29\n",
      "\n",
      "    accuracy                           0.81        53\n",
      "   macro avg       0.81      0.82      0.81        53\n",
      "weighted avg       0.82      0.81      0.81        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify(feats_w2v, targets_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE embeddings with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.83      0.83        24\n",
      "         1.0       0.86      0.86      0.86        29\n",
      "\n",
      "    accuracy                           0.85        53\n",
      "   macro avg       0.85      0.85      0.85        53\n",
      "weighted avg       0.85      0.85      0.85        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify(feats_use, targets_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE embeddings without context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.75      0.73        24\n",
      "         1.0       0.79      0.76      0.77        29\n",
      "\n",
      "    accuracy                           0.75        53\n",
      "   macro avg       0.75      0.75      0.75        53\n",
      "weighted avg       0.76      0.75      0.76        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify(feats_use_wo_context, targets_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS: Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.22 MAE: 0.45\n"
     ]
    }
   ],
   "source": [
    "clf = LinearRegression(positive=True)\n",
    "clf.fit(feats_w2v_sim, targets_w2v)\n",
    "print('MSE:', round(mean_squared_error(targets_w2v, clf.predict(feats_w2v_sim)), 2), \n",
    "      'MAE:', round(mean_absolute_error(targets_w2v, clf.predict(feats_w2v_sim)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = new_df.dropna()['Phrase'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table with scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.993950</td>\n",
       "      <td>апелляционная инстанция</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.973234</td>\n",
       "      <td>акционерное общество</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.935329</td>\n",
       "      <td>арбузная корка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.932819</td>\n",
       "      <td>беспилотный аппарат</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.921375</td>\n",
       "      <td>авторитарная власть</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.219837</td>\n",
       "      <td>мировая судья</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.205752</td>\n",
       "      <td>бархатная революция</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.193058</td>\n",
       "      <td>открытое письмо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.172262</td>\n",
       "      <td>оранжевая революция</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.030798</td>\n",
       "      <td>заднее число</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                   Phrase\n",
       "276  0.993950  апелляционная инстанция\n",
       "226  0.973234     акционерное общество\n",
       "283  0.935329           арбузная корка\n",
       "320  0.932819      беспилотный аппарат\n",
       "186  0.921375      авторитарная власть\n",
       "..        ...                      ...\n",
       "80   0.219837            мировая судья\n",
       "2    0.205752      бархатная революция\n",
       "105  0.193058          открытое письмо\n",
       "97   0.172262      оранжевая революция\n",
       "46   0.030798             заднее число\n",
       "\n",
       "[351 rows x 2 columns]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = pd.concat([pd.Series(clf.predict(feats_w2v_sim)), \n",
    "           phrases], axis=1).sort_values(by=[0], ascending=False)\n",
    "lr[lr[0] < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.to_csv('lr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS: USE embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.24 MAE: 0.49\n"
     ]
    }
   ],
   "source": [
    "clf2 = LinearRegression(positive=True)\n",
    "clf2.fit(feats_use_sim, targets_use)\n",
    "print('MSE:', round(mean_squared_error(targets_use, clf2.predict(feats_use_sim)), 2), \n",
    "      'MAE:', round( mean_absolute_error(targets_use, clf2.predict(feats_use_sim)), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE embeddings with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI: 0.14553640780295107\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=3).fit(feats_use)\n",
    "labels = kmeans.labels_\n",
    "print('ARI:', adjusted_rand_score(targets_use, labels))\n",
    "phrases2 = new_df.dropna().reset_index()['Phrase']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0                         Phrase    1\n",
      "0    0         абсолютное большинство  0.0\n",
      "141  0                 солнечный диск  0.0\n",
      "142  0                  сотовая связь  0.0\n",
      "144  0                   спинной мозг  0.0\n",
      "145  0                   средние века  0.0\n",
      "146  0                  средний класс  0.0\n",
      "147  0                средний уровень  0.0\n",
      "148  0                   средняя рука  0.0\n",
      "149  0                столетняя война  0.0\n",
      "150  0                 торговая война  0.0\n",
      "140  0                солнечное пятно  0.0\n",
      "151  0                   торговый дом  0.0\n",
      "155  0                     узкий круг  0.0\n",
      "158  0                 холодная война  0.0\n",
      "159  0                    худой конец  0.0\n",
      "160  0                 цепная реакция  0.0\n",
      "161  0                    черная дыра  0.0\n",
      "162  0                  черное золото  0.0\n",
      "163  0                  черный молния  0.0\n",
      "164  0                широкая публика  0.0\n",
      "165  0                   широкий круг  0.0\n",
      "154  0                  ударная волна  0.0\n",
      "139  0               солнечная корона  0.0\n",
      "136  0                   слабое звено  0.0\n",
      "133  0              серебряный призер  0.0\n",
      "100  0                острая нехватка  0.0\n",
      "101  0                острое ощущение  0.0\n",
      "102  0                 острый дефицит  0.0\n",
      "103  0                  острый вопрос  0.0\n",
      "104  0                  открытое небо  0.0\n",
      "105  0                открытое письмо  0.0\n",
      "106  0                открытый воздух  0.0\n",
      "109  0              переходный период  0.0\n",
      "110  0              переходный металл  0.0\n",
      "111  0               пограничный слой  0.0\n",
      "113  0                 полная катушка  0.0\n",
      "114  0                  почтовый ящик  0.0\n",
      "115  0                    правый рука  0.0\n",
      "116  0             преклонный возраст  0.0\n",
      "117  0                приборная доска  0.0\n",
      "120  0                   прямая линия  0.0\n",
      "122  0                 разная область  0.0\n",
      "123  0                 реальное время  0.0\n",
      "130  0                   самый разгар  0.0\n",
      "131  0                светлое будущее  0.0\n",
      "132  0              сердечный приступ  0.0\n",
      "167  0           элементарная частица  0.0\n",
      "99   0                острая проблема  0.0\n",
      "169  0                  яркий человек  0.0\n",
      "171  0             аварийная ситуация  1.0\n",
      "312  0                     белая рука  1.0\n",
      "313  0                     белый цвет  1.0\n",
      "314  0                   белый фермер  1.0\n",
      "315  0                  белый человек  1.0\n",
      "316  0                береговая линия  1.0\n",
      "317  0             беременная женщина  1.0\n",
      "318  0             берестяная грамота  1.0\n",
      "319  0                бесконечный ряд  1.0\n",
      "320  0            беспилотный аппарат  1.0\n",
      "311  0                   белая фигура  1.0\n",
      "334  0                    благая цель  1.0\n",
      "340  0              ближнее зарубежье  1.0\n",
      "341  0                   близкий друг  1.0\n",
      "342  0                 богатая страна  1.0\n",
      "343  0                богатый человек  1.0\n",
      "344  0                   богатый опыт  1.0\n",
      "345  0                  богатый купец  1.0\n",
      "347  0                 боевой корабль  1.0\n",
      "349  0                  большая часть  1.0\n",
      "350  0                   большая роль  1.0\n",
      "335  0          благоприятное условие  1.0\n",
      "309  0          бедственное положение  1.0\n",
      "308  0                    бедная руда  1.0\n",
      "300  0               балканская война  1.0\n",
      "174  0              авиационная бомба  1.0\n",
      "351  0               большая проблема  1.0\n",
      "180  0           автомобильная дорога  1.0\n",
      "182  0           автомобильная пробка  1.0\n",
      "194  0              агрессивная среда  1.0\n",
      "195  0          агрессивное поведение  1.0\n",
      "205  0                  азартная игра  1.0\n",
      "211  0         аккумуляторная батарея  1.0\n",
      "233  0              алюминиевый завод  1.0\n",
      "266  0           аналогичная ситуация  1.0\n",
      "267  0         аналогичный показатель  1.0\n",
      "268  0             аналогичный период  1.0\n",
      "273  0               анонимный звонок  1.0\n",
      "277  0               апельсиновый сок  1.0\n",
      "283  0                 арбузная корка  1.0\n",
      "286  0          артериальное давление  1.0\n",
      "287  0          артиллерийский снаряд  1.0\n",
      "288  0            атлантический океан  1.0\n",
      "289  0              атмосферный фронт  1.0\n",
      "290  0             атмосферный воздух  1.0\n",
      "292  0                  атомная бомба  1.0\n",
      "170  0             абсолютный чемпион  1.0\n",
      "98   0                   особое место  0.0\n",
      "352  0                 большая потеря  1.0\n",
      "96   0          октябрьская революция  0.0\n",
      "55   0             карьерная лестница  0.0\n",
      "57   0                квадратный метр  0.0\n",
      "30   0                горячая десятка  0.0\n",
      "29   0                 гоночная серия  0.0\n",
      "28   0                  голодный бунт  0.0\n",
      "61   0                   костный мозг  0.0\n",
      "62   0                 крайний случай  0.0\n",
      "63   0                  красная армия  0.0\n",
      "64   0                  красная черта  0.0\n",
      "65   0                 красная звезда  0.0\n",
      "67   0                   круглый стол  0.0\n",
      "26   0             глубокая древность  0.0\n",
      "68   0                круговая порука  0.0\n",
      "69   0                кубический метр  0.0\n",
      "70   0            кубический километр  0.0\n",
      "54   0                   каменный век  0.0\n",
      "25   0                 глазное яблоко  0.0\n",
      "53   0                    золотой век  0.0\n",
      "51   0                золотой мальчик  0.0\n",
      "37   0                    детский дом  0.0\n",
      "38   0                    детский сад  0.0\n",
      "39   0                    добрая воля  0.0\n",
      "40   0                добрая половина  0.0\n",
      "41   0             домашний кинотеатр  0.0\n",
      "42   0                железная дорога  0.0\n",
      "43   0               железный занавес  0.0\n",
      "44   0                  живое общение  0.0\n",
      "34   0               грубое нарушение  0.0\n",
      "45   0                     живой язык  0.0\n",
      "46   0                   заднее число  0.0\n",
      "47   0               здоровый человек  0.0\n",
      "48   0                     земной шар  0.0\n",
      "49   0                  золотой запас  0.0\n",
      "50   0               золотой миллиард  0.0\n",
      "52   0                  золотой дождь  0.0\n",
      "72   0              ледниковый период  0.0\n",
      "97   0            оранжевая революция  0.0\n",
      "24   0                  главный герой  0.0\n",
      "81   0                мобильная связь  0.0\n",
      "82   0                 мысленный взор  0.0\n",
      "83   0                 мягкая посадка  0.0\n",
      "9    0              великая революция  0.0\n",
      "7    0                  бросовая цена  0.0\n",
      "85   0                 насыщенный пар  0.0\n",
      "86   0           натуральная величина  0.0\n",
      "6    0                  бронзовый век  0.0\n",
      "5    0               большое значение  0.0\n",
      "88   0                   новая газета  0.0\n",
      "89   0                    новая волна  0.0\n",
      "90   0                      новый тип  0.0\n",
      "91   0                   новый взгляд  0.0\n",
      "92   0                   ночной дозор  0.0\n",
      "93   0                    общая черта  0.0\n",
      "2    0            бархатная революция  0.0\n",
      "95   0              окладистая борода  0.0\n",
      "10   0                 великая хартия  0.0\n",
      "11   0                   великий пост  0.0\n",
      "3    0                 бездонный глаз  0.0\n",
      "14   0                взлётная полоса  0.0\n",
      "75   0               лунная программа  0.0\n",
      "21   0               высокое качество  0.0\n",
      "73   0                 личная свобода  0.0\n",
      "12   0              великое множество  0.0\n",
      "13   0                вечная мерзлота  0.0\n",
      "78   0              массовый характер  0.0\n",
      "77   0                 магнитная буря  0.0\n",
      "76   0                   львиная доля  0.0\n",
      "20   0                   высокая мода  0.0\n",
      "19   0              всемирная паутина  0.0\n",
      "17   0                воздушная масса  0.0\n",
      "18   0                воздушный мешок  0.0\n",
      "244  1            американская газета  1.0\n",
      "279  1                 арабские цифры  1.0\n",
      "246  1        американская спецслужба  1.0\n",
      "247  1      американская телекомпания  1.0\n",
      "248  1            американская валюта  1.0\n",
      "301  1                балтийский флот  1.0\n",
      "245  1            американская помощь  1.0\n",
      "243  1             американская фирма  1.0\n",
      "239  1           американская коллега  1.0\n",
      "241  1             американская армия  1.0\n",
      "240  1         американская экономика  1.0\n",
      "249  1         американский президент  1.0\n",
      "238  1           американская сторона  1.0\n",
      "237  1            американская власть  1.0\n",
      "236  1           американская авиация  1.0\n",
      "235  1          американская компания  1.0\n",
      "295  1              афганская граница  1.0\n",
      "296  1            афганская провинция  1.0\n",
      "229  1               альпийский стиль  1.0\n",
      "242  1          американская разведка  1.0\n",
      "250  1           американский военный  1.0\n",
      "256  1         американский экономист  1.0\n",
      "252  1          американский психолог  1.0\n",
      "281  1           арабское государство  1.0\n",
      "278  1                арабская страна  1.0\n",
      "285  1                армянский народ  1.0\n",
      "339  1       ближневосточный конфликт  1.0\n",
      "272  1             английский перевод  1.0\n",
      "271  1               английский текст  1.0\n",
      "270  1              английский король  1.0\n",
      "269  1                английский язык  1.0\n",
      "27   1            голландская болезнь  0.0\n",
      "297  1        афганское правительство  1.0\n",
      "263  1               амурская область  1.0\n",
      "262  1       американское предприятие  1.0\n",
      "261  1          американское общество  1.0\n",
      "260  1     американское правительство  1.0\n",
      "259  1          американский художник  1.0\n",
      "258  1              американский врач  1.0\n",
      "257  1          американский дипломат  1.0\n",
      "228  1                 алтайский край  1.0\n",
      "255  1             американский физик  1.0\n",
      "254  1        американский специалист  1.0\n",
      "253  1            американский индеец  1.0\n",
      "251  1     американский исследователь  1.0\n",
      "280  1                   арабский мир  1.0\n",
      "176  1           австралийский доллар  1.0\n",
      "124  1                римская империя  0.0\n",
      "125  1                   римский папа  0.0\n",
      "126  1             российская сторона  0.0\n",
      "127  1              российская газета  0.0\n",
      "128  1               российский рынок  0.0\n",
      "129  1                    русский дом  0.0\n",
      "206  1               азиатская страна  1.0\n",
      "138  1                 советский союз  0.0\n",
      "135  1                 сибирская язва  0.0\n",
      "306  2                банковское дело  1.0\n",
      "307  2           баскетбольный тренер  1.0\n",
      "22   2                   главная роль  0.0\n",
      "305  2              банковский кредит  1.0\n",
      "310  2         безотходная технология  1.0\n",
      "16   2               военная операция  0.0\n",
      "23   2                главный инженер  0.0\n",
      "304  2              банковский сектор  1.0\n",
      "217  2               активное участие  1.0\n",
      "15   2             властная вертикаль  0.0\n",
      "74   2                  личный состав  0.0\n",
      "134  2              сетевая структура  0.0\n",
      "299  2                  базовый навык  1.0\n",
      "298  2                базовый элемент  1.0\n",
      "137  2           следственный комитет  0.0\n",
      "294  2         атомная промышленность  1.0\n",
      "293  2             атомная энергетика  1.0\n",
      "71   2                 культурный код  0.0\n",
      "291  2         атомная электростанция  1.0\n",
      "143  2                социальная сеть  0.0\n",
      "66   2               крепостное право  0.0\n",
      "60   2           королевский институт  0.0\n",
      "152  2                   точная наука  0.0\n",
      "303  2               банковская тайна  1.0\n",
      "302  2             банковская система  1.0\n",
      "121  2                   рабочая сила  0.0\n",
      "79   2             медицинская сестра  0.0\n",
      "1    2            аналитическая химия  0.0\n",
      "94   2            общественная палата  0.0\n",
      "348  2                 боевые заслуги  1.0\n",
      "107  2        партийное строительство  0.0\n",
      "346  2       богословское образование  1.0\n",
      "4    2               боевое искусство  0.0\n",
      "108  2                пенсионный фонд  0.0\n",
      "87   2                  научная мысль  0.0\n",
      "112  2              политическая сила  0.0\n",
      "8    2               бюджетный кодекс  0.0\n",
      "84   2               налоговый кодекс  0.0\n",
      "80   2                  мировая судья  0.0\n",
      "338  2         благотворительный фонд  1.0\n",
      "337  2         благотворительная цель  1.0\n",
      "153  2               уголовный кодекс  0.0\n",
      "336  2  благотворительная организация  1.0\n",
      "119  2           промышленный шпионаж  0.0\n",
      "333  2           биологическое оружие  1.0\n",
      "332  2           биологический объект  1.0\n",
      "331  2         биологический материал  1.0\n",
      "330  2            биологический закон  1.0\n",
      "329  2             биологический ритм  1.0\n",
      "328  2          биологический возраст  1.0\n",
      "327  2         биологическая мембрана  1.0\n",
      "326  2         биологическая проблема  1.0\n",
      "325  2            биологическая наука  1.0\n",
      "324  2          биологическая система  1.0\n",
      "323  2              бесплатный сервис  1.0\n",
      "322  2         бесплатное образование  1.0\n",
      "321  2              бесплатная услуга  1.0\n",
      "118  2         промышленная революция  0.0\n",
      "59   2           комсомольский правда  0.0\n",
      "284  2        арифметическое действие  1.0\n",
      "31   2        государственный экзамен  0.0\n",
      "196  2       административная реформа  1.0\n",
      "197  2       административная система  1.0\n",
      "198  2        административная власть  1.0\n",
      "199  2       административное деление  1.0\n",
      "200  2      административное давление  1.0\n",
      "201  2         административный центр  1.0\n",
      "202  2        административный ресурс  1.0\n",
      "203  2         административный метод  1.0\n",
      "204  2         административный орган  1.0\n",
      "207  2            академическая среда  1.0\n",
      "208  2        академическая программа  1.0\n",
      "209  2         академический институт  1.0\n",
      "210  2           академическое звание  1.0\n",
      "234  2               амбициозная цель  1.0\n",
      "193  2                аграрный вопрос  1.0\n",
      "212  2          активная деятельность  1.0\n",
      "231  2           альтернативная форма  1.0\n",
      "230  2          альтернативная служба  1.0\n",
      "213  2                активная работа  1.0\n",
      "214  2                 активная форма  1.0\n",
      "227  2          алкогольная продукция  1.0\n",
      "226  2           акционерное общество  1.0\n",
      "215  2             активная поддержка  1.0\n",
      "224  2            актуальная проблема  1.0\n",
      "223  2                 активный отдых  1.0\n",
      "222  2             активный сторонник  1.0\n",
      "221  2              активный участник  1.0\n",
      "220  2             активное население  1.0\n",
      "219  2              активное вещество  1.0\n",
      "218  2              активное действие  1.0\n",
      "232  2        альтернативный источник  1.0\n",
      "216  2                  активная роль  1.0\n",
      "192  2          агитационный материал  1.0\n",
      "190  2                авторское право  1.0\n",
      "282  2                арбитражный суд  1.0\n",
      "58   2                ключевой вопрос  0.0\n",
      "156  2              федеральный орган  0.0\n",
      "157  2            финансовая пирамида  0.0\n",
      "56   2           католическая церковь  0.0\n",
      "32   2            государственный муж  0.0\n",
      "276  2        апелляционная инстанция  1.0\n",
      "275  2  антитеррористическая операция  1.0\n",
      "274  2  антитеррористическая коалиция  1.0\n",
      "33   2               гражданская сила  0.0\n",
      "166  2              электронная почта  0.0\n",
      "168  2               юридическое лицо  0.0\n",
      "172  2     авиационная промышленность  1.0\n",
      "173  2          авиационная федерация  1.0\n",
      "191  2        авторское свидетельство  1.0\n",
      "175  2           авиационный институт  1.0\n",
      "36   2                  движущая сила  0.0\n",
      "265  2            аналитический отдел  1.0\n",
      "264  2            аналитический центр  1.0\n",
      "177  2         автоматическая станция  1.0\n",
      "178  2           автоматическая линия  1.0\n",
      "179  2          автоматическое оружие  1.0\n",
      "181  2   автомобильная промышленность  1.0\n",
      "183  2          автономное учреждение  1.0\n",
      "184  2          автономное сообщество  1.0\n",
      "185  2               автономный робот  1.0\n",
      "186  2            авторитарная власть  1.0\n",
      "187  2             авторитарный режим  1.0\n",
      "188  2       авторитетная организация  1.0\n",
      "189  2            авторитетный журнал  1.0\n",
      "35   2            гуманитарная помощь  0.0\n",
      "225  2              актуальный вопрос  1.0\n"
     ]
    }
   ],
   "source": [
    "cl = pd.concat([pd.Series(labels), pd.Series(phrases2), pd.Series(targets_use)], axis=1)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(cl.sort_values(by=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
